{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "對新聞、討論的文章進行資料前處理，包含斷詞、去除標點符號、計算 tf-idf、特徵選取等等，以利後續的模型訓練。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 CKIP Tagger 進行斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "2024-04-05 20:05:34.566987: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "# 先把我們需要的函數載入\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "ws = WS(\"./data_ckip\") # 斷詞\n",
    "pos = POS(\"./data_ckip\") # 詞性標注\n",
    "ner = NER(\"./data_ckip\") # 命名實體識別 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入資料集\n",
    "import pandas as pd\n",
    "data_dir = '../data/'\n",
    "\n",
    "df_news = pd.read_csv(data_dir + 'news_filtered_labeled.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移除被標註為「持平」的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得 day = n 的標籤結果\n",
    "def get_label(df, n):\n",
    "    return df['label_day' + str(n)].tolist()\n",
    "\n",
    "days = 3\n",
    "\n",
    "# 把標籤為 -1 的 row 全部移除\n",
    "df_news = df_news[df_news['label_day' + str(days)] != -1]\n",
    "Y = get_label(df_news, days) # 取得標籤\n",
    "\n",
    "# 提取正文內容\n",
    "corpus = df_news['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進行斷詞\n",
    "word_sentence_list = ws(corpus, \n",
    "                        sentence_segmentation=True,\n",
    "                        segment_delimiter_set={'?', '？', '!', '！', '。', ',','，', ';', ':', '、', ' ', '.'})\n",
    "# 移除標點符號\n",
    "punc = ['，', '。', '、', '：', '；', '？', '！', '「', '」', '（', '）', '『', '』', '—', '－', '～', '…', '‧', '《', '》', '〈', '〉', '﹏﹏']\n",
    "eng_punc = [',', '.', ':', ';', '?', '!', '(', ')', '[', ']', '&', '@', '#', '$', '%', '-', '_', '*', '/', '\\\\', '+', '=', '>', '<', '\"', \"'\", '’', '‘', '“', '”', ' ']\n",
    "stop_words = ['全文', '日', '月', '年', 'br', '中央社', '公司', '上午', '下午', '日期'] # 停用詞\n",
    "\n",
    "# 只要詞裡面含有數字就移除\n",
    "word_sentence_list = [[word for word in sentence if not any(char.isdigit() for char in word)] for sentence in word_sentence_list]\n",
    "word_sentence_list = [[word for word in sentence if word not in punc] for sentence in word_sentence_list]\n",
    "word_sentence_list = [[word for word in sentence if word not in eng_punc] for sentence in word_sentence_list]\n",
    "word_sentence_list = [[word for word in sentence if word not in stop_words] for sentence in word_sentence_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得 n-gram (n = 1 ~ 3) 的 BOW Count\n",
    "最後會被存在名為 `bow_count` 的 scipy.sparse._csr.csr_matrix 物件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5531, 923189)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(ngram_range=(1, 3))\n",
    "bow_count = bow.fit_transform([' '.join(sentence) for sentence in word_sentence_list])\n",
    "print(bow_count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得 n-gram (n = 1 ~ 3) 的 tf-idf\n",
    "最後會被存在名為 `tfidf` 的 scipy.sparse._csr.csr_matrix 物件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5531, 923189)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tv = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf = tv.fit_transform([' '.join(sentence) for sentence in word_sentence_list])\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square 特徵選取\n",
    "根據標籤內容，計算每個詞的 chi-square 值，並選取前 1000 個詞作為特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5531, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 選取前 1000 個特徵\n",
    "ch2 = SelectKBest(chi2, k=1000)\n",
    "X_chi2 = ch2.fit_transform(tfidf, Y)\n",
    "print(X_chi2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['出席' '電芯' '早餐' '中信 投顧' '長榮 國際 單位' '台塑 智能' '私募' '上市 中櫃 單位' '中櫃 單位' '上市 中櫃'\n",
      " '換約 漲幅' 'jtb' '瑞銀' '張紹豐' '鮮食' '上市 新興' '新興 單位' '上市 新興 單位' '發行 長榮 國際' '火箭'\n",
      " '減資案' '取消' '速報 中航' '盤中 速報 中航' '彭士孝' '旅展' '現金 減資' '先生' '鄭文燦' '年度 分派 股利'\n",
      " '年度 分派' '買回' '協商' '減資' '中航' '修訂案' '外站' '參加' '證券 舉辦 法說會' '江耀宗' '台股 企業日'\n",
      " '企業日' '義大利麵' '元富 證券 舉辦' '長家' '衰退率' '買賣 br' '列車' '參加 元富' '參加 元富 證券' '副駕駛'\n",
      " 'br 盤中 速報' 'br 盤中' '配送' '全家' '盤中 速報' '租回' '爭議' '上市 亞航' '上市 亞航 單位' '亞航 單位'\n",
      " '台灣 高鐵' '閱讀 時報 台北' '太空' '時報 資訊' '速報' '閱讀 時報' '大榮' '嘉里 大榮' '工會' '盈餘 閱讀 時報'\n",
      " '上市 單位' '盈餘 閱讀' 'br' '罷工' '上市 裕民' '投控 單位' '上市 台驊' '上市 台驊 投控' '台驊 投控 單位'\n",
      " '資訊 航運股' '時報 資訊 航運股' '裕民 單位' '上市 裕民 單位' '機師 工會' '嘉里' '閱讀 上市' '年增 閱讀 上市'\n",
      " '上市' '高鐵' '顏益財' '上市 長榮' '單位' '長榮 單位' '上市 長榮 單位' '財經 公告' '營收 年增 閱讀'\n",
      " '年增 閱讀' '閱讀' '機師']\n"
     ]
    }
   ],
   "source": [
    "# 顯示 X_chi2 的特徵名稱\n",
    "feature_names = bow.get_feature_names_out()\n",
    "mask = ch2.get_support() # 這個 mask 會告訴你哪些特徵被選取了\n",
    "selected_features = feature_names[mask]\n",
    "# 從 selected features 中隨機選取 10 個特徵\n",
    "# 取出 chi2 分數最高的 100 個特徵\n",
    "top_100 = np.argsort(ch2.scores_)[-100:]\n",
    "selected_features = feature_names[top_100]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 儲存處理好的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X_chi2\n",
    "from scipy import sparse\n",
    "sparse.save_npz(data_dir + 'X_chi2.npz', X_chi2)\n",
    "sparse.save_npz(data_dir + 'Y.npz', sparse.csr_matrix(Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
