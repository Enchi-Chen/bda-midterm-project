{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "對新聞、討論的文章進行資料前處理，包含斷詞、去除標點符號、計算 tf-idf、特徵選取等等，以利後續的模型訓練。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 CKIP Tagger 進行斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "2024-04-04 15:03:33.944737: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "# 先把我們需要的函數載入\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "ws = WS(\"./data_ckip\") # 斷詞\n",
    "pos = POS(\"./data_ckip\") # 詞性標注\n",
    "ner = NER(\"./data_ckip\") # 命名實體識別 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入資料集\n",
    "import pandas as pd\n",
    "data_dir = '../data/'\n",
    "\n",
    "df_news = pd.read_csv(data_dir + 'news_filtered.csv')\n",
    "\n",
    "# 提取正文內容\n",
    "corpus = df_news['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進行斷詞\n",
    "word_sentence_list = ws(corpus, \n",
    "                        sentence_segmentation=True,\n",
    "                        segment_delimiter_set={'?', '？', '!', '！', '。', ',','，', ';', ':', '、', ' ', '.'})\n",
    "# 移除標點符號\n",
    "punc = ['，', '。', '、', '：', '；', '？', '！', '「', '」', '（', '）', '『', '』', '—', '－', '～', '…', '‧', '《', '》', '〈', '〉', '﹏﹏']\n",
    "eng_punc = [',', '.', ':', ';', '?', '!', '(', ')', '[', ']', '&', '@', '#', '$', '%', '-', '_', '*', '/', '\\\\', '+', '=', '>', '<', '\"', \"'\", '’', '‘', '“', '”', ' ']\n",
    "\n",
    "word_sentence_list = [[word for word in sentence if word not in punc] for sentence in word_sentence_list]\n",
    "word_sentence_list = [[word for word in sentence if word not in eng_punc] for sentence in word_sentence_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得 n-gram (n = 1 ~ 3) 的 BOW Count\n",
    "最後會被存在名為 `bow_count` 的 scipy.sparse._csr.csr_matrix 物件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8617, 1656993)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(ngram_range=(1, 3))\n",
    "bow_count = bow.fit_transform([' '.join(sentence) for sentence in word_sentence_list])\n",
    "print(bow_count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得 n-gram (n = 1 ~ 3) 的 tf-idf\n",
    "最後會被存在名為 `tfidf` 的 scipy.sparse._csr.csr_matrix 物件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8617, 1656993)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tv = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf = tv.fit_transform([' '.join(sentence) for sentence in word_sentence_list])\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square 特徵選取\n",
    "根據標籤內容，計算每個詞的 chi-square 值，並選取前 1000 個詞作為特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8617, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "\n",
    "# 需要預先給定的標籤 Y，我們在這邊暫且先把 Y 隨機分配為 0 或 1\n",
    "Y = np.random.randint(2, size=(len(corpus),)) # 這是假資料！\n",
    "\n",
    "# 選取前 1000 個特徵\n",
    "ch2 = SelectKBest(chi2, k=1000)\n",
    "X_chi2 = ch2.fit_transform(bow_count, Y)\n",
    "print(X_chi2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['現金 方式' '嚴重' '學會' '投資 等級' '航班 編號 it' '修訂案 討論 公司' '束帶' '事業群' '電站' '合約 金額']\n"
     ]
    }
   ],
   "source": [
    "# 顯示 X_chi2 的特徵名稱\n",
    "feature_names = bow.get_feature_names_out()\n",
    "mask = ch2.get_support() # 這個 mask 會告訴你哪些特徵被選取了\n",
    "selected_features = feature_names[mask]\n",
    "# 從 selected features 中隨機選取 10 個特徵\n",
    "print(np.random.choice(selected_features, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 儲存處理好的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X_chi2\n",
    "from scipy import sparse\n",
    "sparse.save_npz(data_dir + 'X_chi2.npz', X_chi2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
